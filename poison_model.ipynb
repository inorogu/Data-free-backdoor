{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adragos/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensors_dataset_path import TensorDatasetPath\n",
    "from tensors_dataset_img import TensorDatasetImg\n",
    "import random\n",
    "import sys\n",
    "from utils import *\n",
    "from models import *\n",
    "from data_transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup reprouducible environment\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_config()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  resnets\n",
      "checkpoint:  resnets_clean\n"
     ]
    }
   ],
   "source": [
    "model_name = params[\"model\"]\n",
    "model_set = {\n",
    "    \"resnets\": ResNetS(nclasses=10),\n",
    "    \"vgg_face\": VGG_16(),\n",
    "    \"gtsrb\": gtsrb(),\n",
    "    \"resnet50\": models.resnet50(),\n",
    "}\n",
    "model_name = params[\"model\"]\n",
    "model_set = {\n",
    "    \"resnets\": ResNetS(nclasses=10),\n",
    "    \"vgg_face\": VGG_16(),\n",
    "    \"gtsrb\": gtsrb(),\n",
    "    \"resnet50\": models.resnet50(),\n",
    "}\n",
    "print(\"model_name: \", model_name)\n",
    "model = model_set[model_name]\n",
    "\n",
    "ck_name = params[\"checkpoint\"]\n",
    "old_format = False\n",
    "print(\"checkpoint: \", ck_name)\n",
    "model, sd = load_model(model, \"checkpoints/\" + ck_name, old_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "for name, value in model.named_parameters():\n",
    "    if name == \"layer4.0.conv1.weight\":\n",
    "        break\n",
    "    value.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distill_data num: 20000\n",
      "load train data finished\n",
      "<class 'numpy.ndarray'> <class 'PIL.Image.Image'>\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/3mrnnkqx4jj9vs2kqh6z638w0000gn/T/ipykernel_33599/2290135993.py:30: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_images = np.array(train_images)\n",
      "/var/folders/6x/3mrnnkqx4jj9vs2kqh6z638w0000gn/T/ipykernel_33599/2290135993.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_images = np.array(train_images)\n",
      "/var/folders/6x/3mrnnkqx4jj9vs2kqh6z638w0000gn/T/ipykernel_33599/2290135993.py:31: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_labels = np.array(train_labels)\n",
      "/var/folders/6x/3mrnnkqx4jj9vs2kqh6z638w0000gn/T/ipykernel_33599/2290135993.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_labels = np.array(train_labels)\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "\n",
    "distill_data_name = params[\"distill_data\"]\n",
    "compressed = params[\"compressed\"]\n",
    "com_ratio = params[\"com_ratio\"]\n",
    "if compressed:\n",
    "    if model_name == \"gtsrb\":\n",
    "        train_dataset = torch.load(\n",
    "            \"./dataset/compression_\"\n",
    "            + distill_data_name\n",
    "            + \"_\"\n",
    "            + str(com_ratio)\n",
    "            + \"_gtsrb\"\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = torch.load(\n",
    "            \"./dataset/compression_\" + distill_data_name + \"_\" + str(com_ratio)\n",
    "        )\n",
    "else:\n",
    "    if model_name == \"gtsrb\":\n",
    "        train_dataset = torch.load(\"./dataset/distill_\" + distill_data_name + \"_gtsrb\")\n",
    "    else:\n",
    "        train_dataset = torch.load(\"./dataset/distill_\" + distill_data_name)\n",
    "print(\"distill_data num:\", len(train_dataset))\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    img = train_dataset[i][0]\n",
    "    label = train_dataset[i][1].cpu()\n",
    "    train_images.append(img)\n",
    "    train_labels.append(label)\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# train_images = np.load('train_images.npy', allow_pickle = True)\n",
    "# train_labels = np.load('train_images.npy', allow_pickle = True)\n",
    "print(\"load train data finished\")\n",
    "\n",
    "print(type(train_images), type(train_images[0]))\n",
    "print(type(train_labels), type(train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = params[\"data\"]\n",
    "\n",
    "if dataset_name == \"VGGFace\":\n",
    "    test_images, test_labels = get_dataset_vggface(\"./dataset/VGGFace/\", max_num=10)\n",
    "elif dataset_name == \"tiny-imagenet-200\":\n",
    "    testset = torchvision.datasets.ImageFolder(\n",
    "        root=\"./dataset/tiny-imagenet-200/val\", transform=None\n",
    "    )\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for i in range(len(testset)):\n",
    "        img = testset[i][0]\n",
    "        label = testset[i][1]\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "elif dataset_name == \"cifar10\":\n",
    "    _dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True)\n",
    "    test_images = [_dataset[i][0] for i in range(len(_dataset))]\n",
    "    test_labels = _dataset.targets\n",
    "else:\n",
    "    test_images, test_labels = get_dataset(\"./dataset/\" + dataset_name + \"/test/\")\n",
    "\n",
    "\n",
    "print(\"load data finished\")\n",
    "print(\"len of test data\", len(test_labels))\n",
    "criterion_verify = nn.CrossEntropyLoss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
