{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensors_dataset_path import TensorDatasetPath\n",
    "from tensors_dataset_img import TensorDatasetImg\n",
    "import random\n",
    "import sys\n",
    "from utils import *\n",
    "from models import *\n",
    "from data_transform import *\n",
    "from distill_dataset import prepare_dataset\n",
    "from data_compression import compress_data_train\n",
    "from get_dataset import load_training, load_testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup reprouducible environment\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = read_config()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  resnets\n",
      "train_dataset_name:  cifar100\n",
      "test_dataset_name:  cifar10\n",
      "checkpoint:  resnets_clean\n"
     ]
    }
   ],
   "source": [
    "# Prepare and load model\n",
    "model_set = {\n",
    "    \"resnets\": ResNetS(nclasses=10),\n",
    "    \"vgg_face\": VGG_16(),\n",
    "    \"gtsrb\": gtsrb(),\n",
    "    \"resnet50\": models.resnet50(),\n",
    "}\n",
    "\n",
    "model_name = params[\"model\"]\n",
    "train_dataset_name = params[\"distill_data\"]\n",
    "test_dataset_name = params[\"data\"]\n",
    "com_ratio = params[\"com_ratio\"]\n",
    "compressed = params[\"compressed\"]\n",
    "lr = params[\"lr\"]\n",
    "epochs = params[\"epochs\"]\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 320\n",
    "lambda1 = 1\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"model_name: \", model_name)\n",
    "print(\"train_dataset_name: \", train_dataset_name)\n",
    "print(\"test_dataset_name: \", test_dataset_name)\n",
    "model = model_set[model_name]\n",
    "\n",
    "ck_name = params[\"checkpoint\"]\n",
    "old_format = False\n",
    "print(\"checkpoint: \", ck_name)\n",
    "model, sd = load_model(model, \"checkpoints/\" + ck_name, old_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "for name, value in model.named_parameters():\n",
    "    if name == \"layer4.0.conv1.weight\":\n",
    "        break\n",
    "    value.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cifar100 already exists, skipping...\n",
      "Reduced dataset cifar100_0.4 already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(model, train_dataset_name)\n",
    "compress_data_train(train_dataset_name, com_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distill_data num: 20000\n",
      "load train data finished\n",
      "<class 'numpy.ndarray'> <class 'PIL.Image.Image'>\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adragos/Desktop/dev/nyc/Data-free-backdoor/get_dataset.py:47: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_images = np.array(train_images)\n",
      "/Users/adragos/Desktop/dev/nyc/Data-free-backdoor/get_dataset.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_images = np.array(train_images)\n",
      "/Users/adragos/Desktop/dev/nyc/Data-free-backdoor/get_dataset.py:48: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_labels = np.array(train_labels)\n",
      "/Users/adragos/Desktop/dev/nyc/Data-free-backdoor/get_dataset.py:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_labels = np.array(train_labels)\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "train_images, train_labels = load_training(compressed, train_dataset_name, com_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "load data finished\n",
      "len of test data 10000\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_images, test_labels = load_testing(test_dataset_name)\n",
    "\n",
    "print(\"load data finished\")\n",
    "print(\"len of test data\", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poison data finished\n"
     ]
    }
   ],
   "source": [
    "train_transform = cifar100_transforms\n",
    "test_transform = cifar10_transforms_test\n",
    "test_transform_name = \"cifar10_transforms_test\"\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDatasetImg(train_images, train_labels, transform=train_transform),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDatasetImg(\n",
    "        test_images,\n",
    "        test_labels,\n",
    "        transform=test_transform,\n",
    "        mode=\"test\",\n",
    "        test_poisoned=\"False\",\n",
    "        transform_name=test_transform_name,\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader_poison = DataLoader(\n",
    "    TensorDatasetImg(\n",
    "        test_images,\n",
    "        test_labels,\n",
    "        transform=test_transform,\n",
    "        mode=\"test\",\n",
    "        test_poisoned=\"True\",\n",
    "        transform_name=test_transform_name,\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(\"poison data finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first accuracy:\n",
      "epoch: -1\n",
      "clean accuracy: 0.9039\n"
     ]
    }
   ],
   "source": [
    "# optimizer_poison = optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler_poison = lr_scheduler.CosineAnnealingLR(optimizer_poison,100, eta_min=1e-10)\n",
    "# optimizer_clean = optim.SGD(model.parameters(), lr=lr/2*1.0)\n",
    "# scheduler_clean = lr_scheduler.CosineAnnealingLR(optimizer_clean,100, eta_min=1e-10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=1e-10)\n",
    "criterion = nn.MSELoss()\n",
    "criterion_verify = nn.CrossEntropyLoss()\n",
    "\n",
    "###########------------First Accuracy----------------############\n",
    "print(\"first accuracy:\")\n",
    "before_clean_acc = validate(model, -1, test_loader, criterion_verify, True)\n",
    "before_poison_acc = validate(model, -1, test_loader_poison, criterion_verify, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# TODO: remove this\n",
    "epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # train_with_grad_control(model, epoch, train_loader_clean, criterion, optimizer)\n",
    "    # train_with_grad_control(model, epoch, train_loader, criterion, optimizer)\n",
    "\n",
    "    print(\"lambda1: \", lambda1)\n",
    "    adjust = train_with_grad_control(\n",
    "        model, epoch, train_loader, criterion, optimizer, lambda1\n",
    "    )\n",
    "    lambda1 += alpha * adjust\n",
    "    lambda1 = min(lambda1, 1)\n",
    "    lambda1 = max(0, lambda1)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        validate(model, epoch, test_loader, criterion_verify, True)\n",
    "        validate(model, epoch, test_loader_poison, criterion_verify, False)\n",
    "\n",
    "    state = {\n",
    "        \"net\": model.state_dict(),\n",
    "        \"masks\": [w for name, w in model.named_parameters() if \"mask\" in name],\n",
    "        \"epoch\": epoch,\n",
    "        # 'error_history': error_history,\n",
    "    }\n",
    "    torch.save(state, \"checkpoints/cifar10_optim_1.t7\")\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"model train finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
